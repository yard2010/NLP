{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "# Use !* because apparently, the word \"not\" is tagged with * \n",
    "START_MARKER = '!*'\n",
    "STOP_MARKER = 'STOP'\n",
    "\n",
    "\n",
    "def prep_part_of_speech(target):\n",
    "    if '+' in target or '-' in target and len(target) > 2 and target != '--':\n",
    "        matches = re.search(r'(.+?)([\\-\\+])', target)\n",
    "        if matches == None:\n",
    "            print(target)\n",
    "        return matches.group(1)\n",
    "    return target\n",
    "\n",
    "\n",
    "def prep_dataset(dataset):\n",
    "    return list(map(lambda sentence: list(map(lambda pair: (pair[0], prep_part_of_speech(pair[1])), sentence)), dataset))\n",
    "\n",
    "\n",
    "# nltk.download(\"brown\")\n",
    "tagged_sents = list(nltk.corpus.brown.tagged_sents(categories=\"news\"))\n",
    "training_size = int(len(tagged_sents) * 0.9)\n",
    "training_data = prep_dataset(tagged_sents[:training_size])\n",
    "test_data = prep_dataset(tagged_sents[training_size:])\n",
    "\n",
    "tags_histogram = defaultdict(int)\n",
    "words_map = defaultdict(lambda: defaultdict(int))\n",
    "for sentence in training_data:\n",
    "    for word, part_of_speech in sentence:\n",
    "        part_of_speech = prep_part_of_speech(part_of_speech)\n",
    "        words_map[word][part_of_speech] += 1\n",
    "        tags_histogram[part_of_speech] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Known words prediction err: 0.0704399684933048\nUnknown words prediction err: 0.75043630017452\nTotal prediction err: 0.14811123293132666\n"
     ]
    }
   ],
   "source": [
    "# Baseline - most likely tag with no other assumptions\n",
    "most_probable_tag = dict()\n",
    "for word in words_map:\n",
    "    most_probable_tag[word] = max(words_map[word].items(), key=lambda pair: pair[1])[0]\n",
    "\n",
    "known_words_count = 0\n",
    "known_hits_count = 0\n",
    "unknown_words_count = 0\n",
    "unknown_hits_count = 0\n",
    "\n",
    "for sentence in test_data:\n",
    "    for word, real_tag in sentence:\n",
    "        if word in most_probable_tag:\n",
    "            predicted_tag = most_probable_tag[word]\n",
    "            known_words_count += 1\n",
    "            if predicted_tag == real_tag:\n",
    "                known_hits_count += 1\n",
    "        else:\n",
    "            predicted_tag = \"NN\"\n",
    "            unknown_words_count += 1\n",
    "            if predicted_tag == real_tag: \n",
    "                unknown_hits_count += 1\n",
    "known_words_accuracy = known_hits_count / known_words_count\n",
    "unknown_words_accuracy = unknown_hits_count / unknown_words_count\n",
    "total_accuracy = (known_hits_count + unknown_hits_count) / (known_words_count + unknown_words_count)\n",
    "\n",
    "print(\"Known words prediction err:\", 1 - known_words_accuracy)\n",
    "print(\"Unknown words prediction err:\", 1 - unknown_words_accuracy)\n",
    "print(\"Total prediction err:\", 1 - total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline Viterbi:\n",
      "Viterbi Known words prediction err: 0.7279171824012602\n",
      "Viterbi Unknown words prediction err: 0.7513089005235603\n",
      "Viterbi Total prediction err: 0.7305890561148212\n"
     ]
    }
   ],
   "source": [
    "# Bigram HMM\n",
    "def viterbi(sentence, transitions, emissions):\n",
    "    n = len(sentence)\n",
    "    \n",
    "    # Calling pi pie so I won't confuse it with PI\n",
    "    pie = [defaultdict(float) for i in range(n + 1)]\n",
    "    for tag in list(tags_histogram.keys()) + [START_MARKER]:\n",
    "        pie[0][tag] = (None, 1.0)\n",
    "    for k in range(1, n + 1):\n",
    "        for tag in list(tags_histogram.keys()) + [START_MARKER]:\n",
    "            max_arg = \"NN\"\n",
    "            max_value = 0\n",
    "            for previous_tag in list(tags_histogram.keys()) + [START_MARKER]:\n",
    "                emission = emissions[sentence[k - 1]][tag]\n",
    "                transition = transitions[(previous_tag, tag)]\n",
    "\n",
    "                pr = pie[k - 1][previous_tag][1] * emission * transition\n",
    "                if pr > max_value:\n",
    "                    max_arg = previous_tag\n",
    "                    max_value = pr\n",
    "            \n",
    "            pie[k][tag] = (max_arg, max_value)\n",
    "\n",
    "    predictions = [None for i in range(n)]\n",
    "    # Pair shape (I miss typescript!): (<current_tag>, (<previous_tag>, <previous_value>))\n",
    "    last_step_max = max(pie[n].items(), key=lambda pair: pair[1][1] * transitions[(pair[1], STOP_MARKER)] )\n",
    "    predictions[n - 1] = last_step_max[0]\n",
    "\n",
    "    for k in range(n - 2, -1, -1):\n",
    "        predictions[k] = pie[k + 2][predictions[k + 1]][0]\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "\n",
    "def print_viterbi_error_rate(dataset, transitions, emissions):\n",
    "    known_words_count = 0\n",
    "    known_hits_count = 0\n",
    "    unknown_words_count = 0\n",
    "    unknown_hits_count = 0\n",
    "    for sentence in dataset:\n",
    "        predictions = viterbi([pair[0] for pair in sentence], transitions, emissions)\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i][0] in words_map:\n",
    "                known_words_count += 1\n",
    "                if sentence[i][1] == predictions[i]:\n",
    "                    known_hits_count += 1\n",
    "            else:\n",
    "                unknown_words_count += 1\n",
    "                if sentence[i][1] == predictions[i]:\n",
    "                    unknown_hits_count += 1\n",
    "            \n",
    "    known_words_accuracy = known_hits_count / known_words_count\n",
    "    unknown_words_accuracy = unknown_hits_count / unknown_words_count\n",
    "    total_accuracy = (known_hits_count + unknown_hits_count) / (known_words_count + unknown_words_count)\n",
    "    print(\"Viterbi Known words prediction err:\", 1 - known_words_accuracy)\n",
    "    print(\"Viterbi Unknown words prediction err:\", 1 - unknown_words_accuracy)\n",
    "    print(\"Viterbi Total prediction err:\", 1 - total_accuracy)\n",
    "\n",
    "\n",
    "def calculate_emissions(words_map, tags_histogram, smoothing_count=0):\n",
    "    emissions = defaultdict(lambda: defaultdict(float))\n",
    "    for word in words_map:\n",
    "        for part_of_speech in words_map[word]:\n",
    "            # emissions[word][part_of_speech] = (words_map[word][part_of_speech] + smoothing_count) / (tags_histogram[part_of_speech] + smoothing_count * len(tags_histogram))\n",
    "            emissions[word][part_of_speech] = 1\n",
    "    return emissions\n",
    "\n",
    "\n",
    "transitions = defaultdict(float)\n",
    "for sentence in training_data:\n",
    "    previous_tag = START_MARKER\n",
    "    for word, tag in sentence:\n",
    "        # tag = prep_part_of_speech(tag)\n",
    "        transitions[(previous_tag, tag)] += 1\n",
    "        previous_tag = tag\n",
    "    transitions[(previous_tag, STOP_MARKER)] += 1\n",
    "for transition in transitions:\n",
    "    if transition[0] == START_MARKER:\n",
    "        transitions[transition] /= len(training_data)\n",
    "    else:\n",
    "        if tags_histogram[transition[0]] == 0:\n",
    "            print(transition, tags_histogram)\n",
    "        transitions[transition] /= tags_histogram[transition[0]]\n",
    "\n",
    "print(\"Baseline Viterbi:\")\n",
    "print_viterbi_error_rate(test_data, transitions, calculate_emissions(words_map, tags_histogram, 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Add-one Viterbi:\n",
      "Viterbi Known words prediction err: 0.7279171824012602\n",
      "Viterbi Unknown words prediction err: 0.7513089005235603\n",
      "Viterbi Total prediction err: 0.7305890561148212\n"
     ]
    }
   ],
   "source": [
    "print(\"Add-one Viterbi:\")\n",
    "print_viterbi_error_rate(test_data, transitions, calculate_emissions(words_map, tags_histogram, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}